%!TEX root = ../thesis.tex

\chapter{Future directions} \label{chap:conclusion}

This thesis presented an investigation of a \gls{bipolar} \gls{OSG}, which at the time of data collection contained over eight million words of user\hyp{}generated text, over 5,800 \glspl{member}, and approximately 9,000 unique \glspl{thread}. Because the main aim of the thesis was to analyse shifts in both wordings and meanings over the course of membership, \gls{SFL}, a theory of language that connects \gls{lexicogrammar} to \glslink{discourse-semantic}{discourse and\slash or semantics} was needed. At the same time, because the research design involved accounting for \emph{all} \glslink{post}{contributions} to the \gls{Forum}, rather than a sample thereof, extensive computational tools and workflows were required. Key tasks from \gls{CL} were reimplemented within a new software tool called \texttt{corpkit}, which provides \gls{CL} practitioners with improved support for symbolic subcorpus structures and annotated and\slash or parsed data. The project, therefore, was very much an interdisciplinary one, spanning qualitative and quantitative, as well as theoretical and computational approaches to language research.

An unavoidable limitation of interdisciplinary work is that it cannot engage with the theory and practices of a given discipline with the level of depth possible in work focussed on a single area of study. The central contribution of the thesis, therefore cannot be, for example, a linear extension of a grammatical system network within \gls{SFL}. Instead, the central contribution is to demonstrate the usefulness of taking practices and ideas from one field and putting them to work in another---in this case, using computational, corpus, and systemic linguistics to better understand \glspl{consumer}' communication about healthcare. Throughout the thesis, an argument has been advanced that the use of state\hyp{}of\hyp{}the\hyp{}art theory, tools and methods, can increase knowledge within the field of healthcare communication. Coupled with future advances, the same approach will also be able to contribute the nascent field of clinical \gls{NLP}, where computational processing of digital natural language leads to the discovery of information that can improve, in one way or another, the practice of medicine. In this chapter, I briefly sketch the kinds of developments that can make such an application of discourse\hyp{}oriented linguistics possible. I then provide a brief summary of the thesis, and a conclusion.

\section{A computational approach to healthcare discourse}

There is increasing recognition within healthcare institutions that state\hyp{}of\hyp{}the\hyp{}art tools and methods from computational linguistics\slash \gls{NLP} can be fruitfully applied to the enormous and ever\hyp{}increasing amount of digital linguistic healthcare data \cite{velupillai2015recent}. As with recent research into the consumer healthcare journey \cite{slade_communicating_2015}, however, most current work has focussed on intra--professional or professional--\gls{consumer} settings, and on the components of the \gls{consumer} journey that take place within the hospital or clinic. A key observation made in this thesis, echoing \textcite{jones_health_2013}, is that consumer journeys can and often do include communication with non\hyp{}professionals, and often leave the confines of formal healthcare institutions. Online, more and more often, people exchange important kinds of meanings that can undoubtedly affect decision\hyp{}making practices regarding their health.

Already, \gls{CMC} data has been used in computational workflows for disease surveillance \cite{kim_use_2013} and public mental health monitoring \cite{paul_social_2016}. Intra--consumer text has been mined in order to detect adverse events and their causes \cite{chee2011predicting}. Addiction cycles can be modelled and predicted by analysis of contributions to an addiction \gls{forum} \cite{maclean_forum77:_2015}; successful rhetorical strategies for counsellors can be identified by comparing linguistic features of the session to follow\hyp{}up survey results \cite{althoff_counseling_2016}. Despite the enormous promise of this emerging area of research, however, current approaches have serious shortcomings in terms of their conceptualisation of what language is and how it works. Many such studies treat texts as nothing but lists or sets of tokens, despite the fact that decades of work in functional and discourse linguistics have shown the centrality of both grammar and context to the meaning\hyp{}making process.

\subsection{Necessary developments}

\texttt{corpkit}, the tool developed for the analysis of the \glslink{Forum}{Bipolar Forum} is a step in the direction of a computational discourse analysis that accounts for the role of grammar and context, as well as and the multifunctionality of language. Already, the tool can generate a quantitative description of shallow features of a \gls{corpus} with a single command (\mintinline{bash}{calculate features of corpus}, in the syntax of the interpreter). Extremely delicate querying of \gls{lexicogrammar}, as shown throughout Chapters \ref{chap:interpersonal} and \ref{chap:experiential}, is also facilitated by the tool. The output of these searches could foreseeably improve dramatically on the bag\hyp{}of\hyp{}words approach for many discourse\hyp{}oriented tasks. At the same time, however, tool development is no substitute for the expertise of qualitative researchers. Many discourse\hyp{}analytic studies involve manual classification of instances of language based on functional\hyp{}semantic features that no current computational method can accurately identify. Locher's \parencite*{locher2006advice} use of \gls{XML} tags to annotate instances of advice provision with semantic information is just one of many examples of high quality resources that could be re\hyp{}used as training data for machine learning classification tasks. Such an approach could put the insights generated in qualitative and corpus\hyp{}assisted discourse studies to use on exponentially larger scales, and in novel domains. The first needed development, therefore, is a conduit through which qualitative and computational social scientists can share theory, tools, and data. What this conduit may look like, however, remains for the most part unknown.

\subsubsection{Automatic annotation of the semantic stratum}

At many points in the investigation, it became apparent that existing methods for lexicogrammatical parsing could not be used to directly access \gls{discourse-semantic} features of texts. Even relatively simple semantic relationships, such as the relationship between \emph{diagnose} and \emph{diagnosis} (the latter being a reconfiguration of the former as a participant, rather than a process) is not annotated by any currently popular \gls{NLP} system. Any project interested in \glspl{discourse-semantic}, however, would benefit from explicit annotation of grammatical metaphor---for many applications, \gls{lexicogrammar} is only of interest because it the most convenient entry point to meaning\hyp{}making at the rank of clause and below. Semantic annotation, while an ideal solution, is a task that remains in its infancy \cite[see][]{rayson2004ucrel}.

The most obvious challenge is that a useful automated semantic analysis is predicated on a conceptualisation of register, and of the text as an ongoing exchange. The Speech Function of a given Mood Type, for example, depends on the overall Tenor of the text, and on the content of adjacent clauses and moves. Most current approaches to parsing, however, do not exploit or respond to registerial information in any way. From a systemic\hyp{}functional standpoint, it seems plausible to suggest that a \gls{discourse-semantic} layer could be generated via oscillation between parser output (that is, the \emph{n}\hyp{}best parses of a clause\slash sentence) and a quantitative model of the register of a text. The parser could both develop and refine a semantic representation of the clause, and perform re\hyp{}ranking of the parses, so that the most likely lexicogrammatical parse is one that is sensitive to genre, register, individual speakers and the text as an interactive, unfolding event.

%\gls{SFL} has long been aligned with what have become mainstream thinking in computational linguistics: the notion of linguistic choice as probabilistic, and of lexis and grammar existing as opposite ends of the same system, were recognised in \gls{SFL} long before more popular grammars and theories \cite[compare][]{bod_probabilistic_2003,halliday_corpus_1991} \cite{matthiessen2014registerial}.

\section{Summary of the thesis}

The primary aim of the thesis was to investigate linguistic change over the course of membership in an \gls{OSG}. This was to be accomplished \textbf{with} corpus\slash computational linguistic tools and methods, \textbf{via} \gls{SFL} as theory and \gls{SFG} as grammar of language, \textbf{for} the burgeoning area of \gls{HC} research. Four research questions were developed and addressed. They are summarised in the four sections below.

\subsection{Lexicogrammar at risk over membership}

\sctext{Mood} and \sctext{Modality} features of language vary considerably and consistently over the course of membership in the \glslink{Forum}{Bipolar Forum}, with a steady increase in imperatives, and modalised declarative Mood. In terms of Subject choice, first person is displaced by second person over time. A number of \sctext{Transitivity} features are also at risk. At the level of lexis, jargonised participants displace lay terms found in newcomers' talk (\emph{doctor} $\rightarrow$ \emph{doc} $\rightarrow$ \emph{pdoc\slash tdoc}). In terms of processes, \emph{wondering} and \emph{thanking} give way to processes of \emph{welcoming}; \emph{feeling} is replaced by \emph{thinking}, and violent and emotional processes (\emph{killing}, \emph{suffering}) are replaced by more positive ones (\emph{hugging}, \emph{recommending}, \emph{improving}). Processes selected for sustained analysis showed shifts in the participants and circumstances that they typically select. The process of \emph{diagnosis} shifts from being modified temporally to being modified for veracity (\emph{recently diagnosed} $\rightarrow$ \emph{accurately diagnosed}). Over the membership course, the ways in which \gls{Forum} users ascribe \gls{bipolar} to themselves and others also undergo longitudinal change: while most \gls{Forum} contributors tend to use identifying relational processes (\emph{I am bipolar}), in late stages of membership, there is a shift toward construal of people as possessors and Agents over \gls{bipolar} (\emph{I have bipolar}). %, granting a symbolic agency that makes finding \emph{stability} and \emph{balance} possible.

\subsection{Linking lexicogrammar to meaning}

Shifting upward from lexicogrammar on the hierarchy of stratification allows insight into changes in the kinds of meanings being made. In the \glslink{Forum}{Bipolar Forum}, there are longitudinal differences in both interpersonal and experiential semantics. Interpersonally, \glslink{member}{users} shift from requesting information and support to providing it. Modalised declaratives are used by newcomers to provide an account of their healthcare journey leading up to the present. In veteran talk, however, the modalised declarative is more commonly a realisation of advice. Experientially, users increasingly construe themselves and other healthcare consumers as active patients, and represent the relationship between the professional and consumer as more equal in terms of who is responsible for bringing about change.

\subsection{Linking back to research}

The third research question is centred on the implications of the case study and the developed methods for corpus linguistics, \gls{SFL}, and healthcare communication research. Methodologically, a number of computational linguistic tools and methods (e.g. dynamic corpus structures, parsing, programmatic workflows) were brought into the purview of corpus linguistics and corpus-assisted discourse research for the first time. At the level of theory, the thesis generated an account of the components of the consumer healthcare journey that take place outside hospitals and clinics. Online intra--consumer interaction was shown to be a rich resource for learning about how Forum users construe \gls{bipolar} and the world of healthcare with which they engage. 

\subsection{Needed tools and methods}

A major outcome of the thesis was the development of a new tool for \gls{CL}, which extends upon the functionality of existing tools by better engagement with corpus metadata and structure, and by allowing the user to exploit automatic annotation and parsing. The tool has three user interfaces, each of which is tailored for differing levels of familiarity with computer programming and the command line. This maximises potential take\hyp{}up of the tool within a wide array of fields, ranging from computer science to the digital humanities. The simplest of these---the \glslink{GUI}{graphical interface}---requires no knowledge of programming, and only a basic knowledge of constituency, dependency, or systemic grammar. The most powerful---the Python \gls{API}---is flexible enough for incorporation within the kinds of workflows outlined in the previous section, and thus contributes to the nascent fields of computational social sciences and clinical \gls{NLP}. Public use of the tool has increased steadily since its initial release. Engagement with users via GitHub suggests that all three interfaces are in use, and that users span a number of fields within and outside linguistics, as well as industry.

%At many points in the investigation, it became apparent that little more could be said or done automatically---concordancing or thematic categorisation was needed in order to properly understand the meanings being made by an automatically identifiable component within the \gls{lexicogrammar}. Complete manual analysis of \glspl{corpus} available today is not feasible, even with teams of well-trained researchers. Therefore, automating the resource-intensive parts of discourse analysis became a key goal. While we can indeed learn things through qualitative analysis that we can not learn through quantification, it is obvious enough that qualitative research, regardless of its depth of insight, is expensive, difficult to reproduce, and ultimately less likely to affect policy.

%Ideally, however, so long as an automatic process can accomplish a research task without a loss of accuracy, it should be preferred: when compared to manual processing, automatic processing is faster, cheaper, more scalable, more transparent and more easily applied to new data.

%There were two recurring roadblocks throughout the case study. First was the use of constituency and dependency parses for extraction of \gls{SFG} features. Many of the subtle kinds of distinctions made in \gls{SFL} between metafunctions are simply not recoverable from dependency labels. Second is the notion of uncovering \gls{discourse-semantic} meanings by searching lexicogrammar. Where this is possible, it is still heavily reliant on linguistic intuition, and manual reading of concordances. In many cases, however, the task is simply not possible.

\section{Conclusion}

This thesis identified shifts in words, wordings, discourses and meanings over the course of membership in \glslink{Forum}{Bipolar Forum}, an online health support group. This task involved the application of a theory of language (\gls{SFL}) capable of distinguishing between interpersonal and ideational meaning and their realisations within grammatical systems. I found that \gls{Forum} \glslink{member}{users}' language undergoes a number of changes over the membership course. Most obviously, their language use increasingly reflects alignment with a biomedical account of \gls{bipolar}, and a \gls{consumercentred} model of the healthcare journey. Meanwhile, the thesis involved extensive development of new tools and methods for identifying linguistic change. These tools are now publicly available and in use.

Looking toward the future, it is clear that developments in statistical \gls{NLP} will lead to greater accuracy in a number of tasks integral to automatic computational modelling and understanding of texts. At the same time, however, computational approaches would do well to incorporate insights from functional linguistic theory, which has shown how lexis and grammar operate as a single stratum to realise meaning, and from discourse analysis, where empirically informed functional\hyp{}semantic categorisation could be repurposed as training data for computational models. Within the context of healthcare, such an interdisciplinary approach to discourse could foreseeably lead not only to the generation of new knowledge and theory, but eventually to improved clinical practice and health outcomes as well.

%The ability of the methods presented here depends for the most part on predictable developments in computational linguistics and \gls{NLP}. The accuracy of parsing, named entity recognition and referent tracking will certainly improve, especially as a result of advances in machine learning and neural network approaches. Richer grammars for \glslink{lexicogrammar}{lexicogrammatical} parsing, \gls{discourse-semantic} parsing and computational register modelling, however, are being worked on by only small groups of researchers. Improvement in connection between health discourse on the social web and clinical outcomes and responses thus depends on a cyclical development process, where improvements in \gls{NLP} resources can be used to show improvements in online health research, and where better online health research inspires further advances in \gls{NLP}.


